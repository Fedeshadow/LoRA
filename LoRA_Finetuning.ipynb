{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwfXT98e5hQc"
      },
      "source": [
        "# Neural Networks for Data Science Applications\n",
        "## End-of-term homework: Advanced transfer learning\n",
        "\n",
        "**Name**: Federico Argilli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V6Ph3UT44Xo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkYGd_WY_2nq"
      },
      "outputs": [],
      "source": [
        "# To ensure reproducible results (as much as possible)\n",
        "tf.keras.utils.set_random_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE7pCfZK2G5M"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzThDtr4VJ5x"
      },
      "source": [
        "I am a passionate supporter of online gaming, and one relevant issue within the online gaming community is the toxicity exhibited by some players. Addressing this problem is indeed a challenging task.\n",
        "\n",
        "As I will show in the model section, identifying toxic behavior is difficult with standard sentiment analysis. This is because certain sentences flagged as negative may actually make complete sense within the context of the game.\n",
        "\n",
        "The dataset selected for this project consists of an extensive collection of chat logs from one of the most famous multiplayer online games: League of Legends. It is available on [Kaggle](https://www.kaggle.com/datasets/simshengxue/league-of-legends-tribunal-chatlogs) and originates from a platform provided by the game's company, which made these logs accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FpQj4F8n20LI",
        "outputId": "a49e4469-28a9-47a8-d0dd-b8ad14b2b895"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cae5fb32-e7b0-4b9b-bbdf-10702bdb2222\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cae5fb32-e7b0-4b9b-bbdf-10702bdb2222\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "#### Uncomment to setup kaggle key\n",
        "files.upload()  # upload kaggle.json\n",
        "! mkdir -p ~/.kaggle\n",
        "! mv kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pH2_0TDYtoR",
        "outputId": "c08c0fb6-8f28-483e-c5e6-9e57ba9f5e92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading league-of-legends-tribunal-chatlogs.zip to /content\n",
            " 97% 81.0M/83.8M [00:01<00:00, 91.9MB/s]\n",
            "100% 83.8M/83.8M [00:01<00:00, 80.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download and extract data\n",
        "!kaggle datasets download -d simshengxue/league-of-legends-tribunal-chatlogs\n",
        "!unzip -q league-of-legends-tribunal-chatlogs.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV6kEACIYyed"
      },
      "outputs": [],
      "source": [
        "# loading the data as a pandas DataFrame\n",
        "with open(\"input-data.json\",\"r\") as f:\n",
        "  raw_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIYHzD_4Y2IU"
      },
      "outputs": [],
      "source": [
        "# dropping non-relevant columns\n",
        "df = pd.DataFrame(raw_data[\"Messages\"])\n",
        "df.drop([\"IsAllChat\",\"IsAlly\",\"ReferredChampions\"],axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClWuUn46BTQX"
      },
      "source": [
        "The relevant columns for this project are:\n",
        "- `IsToxic`: wheter the text is toxic or not, flagged by human control\n",
        "- `Content`: the actual text message\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Mgk1LHnsZohQ",
        "outputId": "4e0a0117-1347-402c-ecfb-cac05780b16a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6d8eefb-a01f-44d3-be17-ae12429ccc58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsToxic</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>gold 2 zed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>IIII</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>nice premade lie :o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>ISI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>smiteless pls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>smiteless pls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>riven?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>report top no help jnh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>warded there</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6d8eefb-a01f-44d3-be17-ae12429ccc58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6d8eefb-a01f-44d3-be17-ae12429ccc58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6d8eefb-a01f-44d3-be17-ae12429ccc58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae2be142-5d59-4234-adf9-4d1bbce5d1ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae2be142-5d59-4234-adf9-4d1bbce5d1ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae2be142-5d59-4234-adf9-4d1bbce5d1ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   IsToxic                 Content\n",
              "0    False              gold 2 zed\n",
              "1    False                    IIII\n",
              "2    False     nice premade lie :o\n",
              "3    False                     ISI\n",
              "4    False           smiteless pls\n",
              "5    False           smiteless pls\n",
              "6    False                  riven?\n",
              "7    False  report top no help jnh\n",
              "8    False            warded there\n",
              "9    False                       K"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URjO_8GxB-Gp"
      },
      "source": [
        "#### Preprocess, test and train\n",
        "The model (T5) was trained on the SST2 dataset, thus for sentiment classification we can use the prefix `\"sst2 sentence:\"`.\\\n",
        "In order to create the training and test datasets we have to concatenate the prefix to all sentences and transform the `IsToxic` column with the actual labels to predict: positive or negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzsoWJFPZKWY"
      },
      "outputs": [],
      "source": [
        "task_prefix = \"sst2 sentence: \"  # equivalent to say \"sentiment analysis sentence:\"\n",
        "df[\"Sentence\"] = task_prefix + df[\"Content\"].map(str)   # insert the prefix\n",
        "\n",
        "# create a column with the actual predicted label\n",
        "df[\"label\"] = df[\"IsToxic\"].apply(lambda x: \"negative\" if x else \"positive\")  # if toxis --> \"negative\", if not toxis --> positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccvEWTYUOIYd"
      },
      "source": [
        "We can see below the final version of the dataset that will be later tokenized in order to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uh_DbmFGZfAu",
        "outputId": "aaa17ec2-d679-4acc-e7d1-ee4813340f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df4c6462-b378-4ed9-826c-42d8abcfc2bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sst2 sentence: gold 2 zed</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sst2 sentence: IIII</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sst2 sentence: nice premade lie :o</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sst2 sentence: ISI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sst2 sentence: smiteless pls</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4c6462-b378-4ed9-826c-42d8abcfc2bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df4c6462-b378-4ed9-826c-42d8abcfc2bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df4c6462-b378-4ed9-826c-42d8abcfc2bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b71a159-4b1b-475c-9ec3-cc65ded5d09d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b71a159-4b1b-475c-9ec3-cc65ded5d09d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b71a159-4b1b-475c-9ec3-cc65ded5d09d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                             Sentence     label\n",
              "0           sst2 sentence: gold 2 zed  positive\n",
              "1                 sst2 sentence: IIII  positive\n",
              "2  sst2 sentence: nice premade lie :o  positive\n",
              "3                  sst2 sentence: ISI  positive\n",
              "4        sst2 sentence: smiteless pls  positive"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[[\"Sentence\",\"label\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dhGUJNvaBBk"
      },
      "outputs": [],
      "source": [
        "# split into train and test\n",
        "train_df = df.sample(n=15000, random_state=123)\n",
        "test_df = df.drop(train_df.index).sample(n=2000, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i1Jr0mQ7lRY"
      },
      "source": [
        "### Advanced transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm-iFz1iCSue"
      },
      "source": [
        "**DESCRIPTION OF THE CODE**\n",
        "\n",
        "The model I chose is Google's [T5](https://arxiv.org/abs/1910.10683). It adheres to the standard encoder-decoder architecture and operates as a multi-task model in the text-to-text format.\\\n",
        "I opted for the \"small\" version (60M parameters) as it seemed like the most practical choice for efficient training and execution on limited resources. Despite its smaller size, it still managed to yield good results after the fine-tuning process.\n",
        "\n",
        "I aimed to fine-tune the model using LoRA's approach. Following the LoRA [paper's](https://arxiv.org/abs/2106.09685) recommendations, I applied LoRA to the $q$ and $v$ matrices in the attention layers, both within the encoder and decoder of the model.\n",
        "\n",
        "The `transformer` module is used solely for downloading the model from [Hugging Face](https://huggingface.co/google-t5/t5-small). Everything else, from generation to defining LoRA components and training, is accomplished in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGeQDlEpJ-3b",
        "outputId": "a885841a-a882-4115-fe04-f972cf6b8591"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5TokenizerFast, TFT5ForConditionalGeneration\n",
        "import transformers\n",
        "\n",
        "tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")  # load the model with tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v02dsLvfkgO",
        "outputId": "9e747f0c-6565-4cbf-ef1b-421ffc55843c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tft5_for_conditional_generation\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " shared (Embedding)          multiple                  16449536  \n",
            "                                                                 \n",
            " encoder (TFT5MainLayer)     multiple                  35330816  \n",
            "                                                                 \n",
            " decoder (TFT5MainLayer)     multiple                  41625344  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60506624 (230.81 MB)\n",
            "Trainable params: 60506624 (230.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU3BigKPGR9d"
      },
      "source": [
        "An example of what I anticipated above.\\\n",
        "Here there are some example sentences that are not toxic in the context of the game but are miss-classfied by the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7b71W_-ayg9",
        "outputId": "384ced0f-0839-493f-86ae-15367909b008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('We need more need kills', 'negative') ('ROFL', 'positive') ('hard focus the enemy', 'negative')\n"
          ]
        }
      ],
      "source": [
        "task_prefix = \"sst2 sentence: \"\n",
        "\n",
        "sentences = [\"We need more need kills\", \"ROFL\", \"hard focus the enemy\"]\n",
        "\n",
        "# append the prefix to each sentence and return the tokenized ids\n",
        "inputs = tokenizer([task_prefix + sentence for sentence in sentences], return_tensors=\"tf\", padding=True)\n",
        "\n",
        "# generate the response from the model\n",
        "output_sequences = model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        ")\n",
        "\n",
        "labels = tokenizer.batch_decode(output_sequences, skip_special_tokens=True) # decode the response\n",
        "\n",
        "print(*zip(sentences,labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK1gPw2vbPJB"
      },
      "source": [
        "#### LoRA model\n",
        "I had to define a new type of layer (`LoraDense`) in order to inject low rank matrices in the model.\n",
        "The `dense` attribute of this new model represent the orginal dense layer of $q$ or $v$ in the attention layers.\n",
        "\n",
        "I also had to create a model-trainer subclass to customize the fit method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9cxX-bUbTfb"
      },
      "outputs": [],
      "source": [
        "# tensorflow implementation of the pytorch code from the orginal paper\n",
        "# https://github.com/microsoft/LoRA/blob/main/loralib/layers.py\n",
        "class LoraDense(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, config, rank=8, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.dense_config = config      # initialize and copy the original dense\n",
        "    self.dense = tf.keras.layers.Dense.from_config(self.dense_config)\n",
        "    self.dense.trainable = False   # set the original dense layer as non trainable\n",
        "\n",
        "    self.r = rank\n",
        "\n",
        "  def build(self, dense_build_config, weights):\n",
        "    in_dim = weights[0].shape[0]\n",
        "    out_dim = weights[0].shape[1]\n",
        "\n",
        "    self.dense.build_from_config(dense_build_config)\n",
        "    self.dense.set_weights(weights)          # copy the original weight of the model\n",
        "\n",
        "    # Add low rank matrices\n",
        "    self.B = self.add_weight(shape=(in_dim,self.r),\n",
        "                              initializer='zeros',    # B initialized with all zeros\n",
        "                              trainable=True,\n",
        "                              name=\"Lora_B\")\n",
        "    self.A = self.add_weight(shape=(self.r,out_dim),\n",
        "                              initializer='random_normal',   # A initialized at random\n",
        "                              trainable=True,\n",
        "                              name=\"Lora_A\")\n",
        "    self.built = True\n",
        "\n",
        "  def call(self,x):\n",
        "    W = self.dense(x)  # orginal output\n",
        "    BA = self.B @ self.A\n",
        "\n",
        "    return W + x@BA  # modified output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVK8KtTEb0NB"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit\n",
        "class LoraCustomTrainer(TFT5ForConditionalGeneration):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__(*args,**kwargs)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self,data):\n",
        "    x,y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = self(input_ids=x, labels = y).loss # compue the loss\n",
        "\n",
        "    trainable_variables = []\n",
        "\n",
        "    # we need to iterate over all the layers because model.trainable_weights does not return weights\n",
        "    for l in self.encoder.submodules:\n",
        "      if isinstance(l,transformers.models.t5.modeling_tf_t5.TFT5Attention):\n",
        "        trainable_variables += l.q.trainable_weights  # add lora parameters from q\n",
        "        trainable_variables += l.v.trainable_weights  # add lora parameters from v\n",
        "\n",
        "    for l in self.decoder.submodules:\n",
        "      if isinstance(l,transformers.models.t5.modeling_tf_t5.TFT5Attention): # same cycle on the decoder\n",
        "        trainable_variables += l.q.trainable_weights\n",
        "        trainable_variables += l.v.trainable_weights\n",
        "\n",
        "    grads = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    self.optimizer.apply_gradients(zip(grads, trainable_variables))  # apply gradients\n",
        "\n",
        "    return {\"loss\":loss}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJDIJHgrftM-",
        "outputId": "a27e4fa3-c399-44e1-df8f-ab3f98b89ad6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing LoraCustomTrainer.\n",
            "\n",
            "All the weights of LoraCustomTrainer were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LoraCustomTrainer for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "trainer = LoraCustomTrainer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD7TNYNAfXVf"
      },
      "source": [
        "Below I replace the model's layers with the new LoRA layers and initialize them with the original configuration and weigths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElViRZzWKGd8"
      },
      "outputs": [],
      "source": [
        "# injection of LoraDense layers\n",
        "for l in trainer.encoder.submodules + trainer.decoder.submodules:\n",
        "  l.trainable = False  # mark all layers as not trainable\n",
        "\n",
        "  if isinstance(l,transformers.models.t5.modeling_tf_t5.TFT5Attention):  # select only attention layers\n",
        "\n",
        "    # get original dense layer configuration and weights\n",
        "    build_config_q, build_config_v = l.q.get_build_config(), l.v.get_build_config()\n",
        "    config_q, config_v = l.q.get_config(), l.v.get_config()\n",
        "    weights_q, weights_v = l.q.get_weights(), l.v.get_weights()\n",
        "\n",
        "    l.q = LoraDense(config_q)  # replace the dense layer for q in the original attention layer\n",
        "    l.q.build(build_config_q, weights_q)\n",
        "\n",
        "    l.v = LoraDense(config_v)  # replace the dense layer for v in the original attention layer\n",
        "    l.v.build(build_config_v, weights_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VToo3VoYbCBq"
      },
      "source": [
        "#### Training and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxQKHpMXc396",
        "outputId": "457babab-0cb5-40e7-e59f-21a6974cbaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n",
            "['Lora_B:0', 'Lora_A:0']\n"
          ]
        }
      ],
      "source": [
        "# mark the embeddings as not trainable\n",
        "trainer.shared.trainable=False\n",
        "\n",
        "# check that only the LoRA matrices are trainable weights\n",
        "for l in trainer.encoder.submodules:\n",
        "  if isinstance(l,transformers.models.t5.modeling_tf_t5.TFT5Attention):\n",
        "    print([weight.name for weight in l.q.trainable_weights])\n",
        "    print([weight.name for weight in l.v.trainable_weights])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4NfMkwPbDSV"
      },
      "outputs": [],
      "source": [
        "# tokenize the training dataset\n",
        "X_train = tokenizer(train_df[\"Sentence\"].to_list(), return_tensors=\"tf\", padding=True).input_ids\n",
        "y_train = tokenizer(train_df[\"label\"].to_list(), return_tensors=\"tf\",padding=True).input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiNoxz24cnZe"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "trainer.compile(optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLQ-wia9cvio",
        "outputId": "c65d535f-c654-4c82-c7f3-e14e21eb7c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "469/469 [==============================] - 89s 138ms/step - loss: 0.2609\n",
            "Epoch 2/3\n",
            "469/469 [==============================] - 63s 135ms/step - loss: 0.2338\n",
            "Epoch 3/3\n",
            "469/469 [==============================] - 62s 133ms/step - loss: 0.2334\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7af15c3fc7f0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.fit(X_train,y_train, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSa9AgMugDX_"
      },
      "source": [
        "Below we can check the results on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIrB2AtXdELb"
      },
      "outputs": [],
      "source": [
        "# tokenize the test dataset\n",
        "inputs = tokenizer(test_df[\"Sentence\"].to_list(), return_tensors=\"tf\", padding=True)\n",
        "label = tokenizer(test_df[\"label\"].to_list(), return_tensors=\"tf\",padding=True)\n",
        "\n",
        "# generate with the fine-tuned model\n",
        "lora_output_sequences = trainer.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"]\n",
        ")\n",
        "\n",
        "# generate with the original model\n",
        "base_output_sequences = model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJhSz4mZdHTo",
        "outputId": "da70a85e-dcca-478c-80a3-120efda31344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the finetuned model: 0.8055\n",
            "Accuracy of the base model: 0.5145\n"
          ]
        }
      ],
      "source": [
        "new_acc = sum(test_df[\"label\"] == tokenizer.batch_decode(lora_output_sequences, skip_special_tokens=True))/len(test_df)\n",
        "old_acc = sum(test_df[\"label\"] == tokenizer.batch_decode(base_output_sequences, skip_special_tokens=True))/len(test_df)\n",
        "\n",
        "print(f\"Accuracy of the finetuned model: {new_acc}\")\n",
        "print(f\"Accuracy of the base model: {old_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MX-UKdloqKL"
      },
      "source": [
        "The fine-tuned model demonstrated a substantial improvement over the base model's 50% accuracy, with the training of only a small fraction of parameters using LoRA.\\\n",
        "While there is room for enhancements, this result remains remarkable, particularly considering the modest size of the model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XXUhR5ZH9PKQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
